{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3863dd5-9e6c-4efb-936f-074bdd4afcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62de19ee-ec03-419a-9a0d-59e4fa4fbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉\n",
    "    transforms.RandomRotation(15), #隨機旋轉圖片\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4eb766-bd0a-4ca3-aeca-1f6b068d463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Construct datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "train_set = DatasetFolder(\"~/data/food-11-big/training\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "valid_set = DatasetFolder(\"~/data/food-11-big/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "test_set = DatasetFolder(\"~/data/food-11-big/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "# Construct data loaders.\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers = 4, pin_memory = True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers = 4, pin_memory = True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6c056e-fc7c-4d19-9cda-c74b59a85705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=11):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512*4*4, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        #print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea450e6-74d2-485e-b699-2e011ad833a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001/080 ] loss = 2.26003, acc = 0.26965\n",
      "[ Valid | 001/080 ] loss = 2.02232, acc = 0.29365\n",
      "[ Train | 002/080 ] loss = 1.78556, acc = 0.37965\n",
      "[ Valid | 002/080 ] loss = 1.79945, acc = 0.37599\n",
      "[ Train | 003/080 ] loss = 1.66471, acc = 0.42288\n",
      "[ Valid | 003/080 ] loss = 1.86408, acc = 0.36806\n",
      "[ Train | 004/080 ] loss = 1.56303, acc = 0.46112\n",
      "[ Valid | 004/080 ] loss = 1.62990, acc = 0.45000\n",
      "[ Train | 005/080 ] loss = 1.46024, acc = 0.49830\n",
      "[ Valid | 005/080 ] loss = 1.66595, acc = 0.43433\n",
      "[ Train | 006/080 ] loss = 1.38374, acc = 0.52443\n",
      "[ Valid | 006/080 ] loss = 1.56238, acc = 0.46607\n",
      "[ Train | 007/080 ] loss = 1.30334, acc = 0.55408\n",
      "[ Valid | 007/080 ] loss = 1.45745, acc = 0.52073\n",
      "[ Train | 008/080 ] loss = 1.23630, acc = 0.57974\n",
      "[ Valid | 008/080 ] loss = 1.43146, acc = 0.52123\n",
      "[ Train | 009/080 ] loss = 1.16997, acc = 0.59484\n",
      "[ Valid | 009/080 ] loss = 1.32979, acc = 0.55942\n",
      "[ Train | 010/080 ] loss = 1.10665, acc = 0.62724\n",
      "[ Valid | 010/080 ] loss = 1.32638, acc = 0.54603\n",
      "[ Train | 011/080 ] loss = 1.05069, acc = 0.64521\n",
      "[ Valid | 011/080 ] loss = 1.27981, acc = 0.56458\n",
      "[ Train | 012/080 ] loss = 0.99818, acc = 0.65998\n",
      "[ Valid | 012/080 ] loss = 1.38266, acc = 0.55208\n",
      "[ Train | 013/080 ] loss = 0.93771, acc = 0.67791\n",
      "[ Valid | 013/080 ] loss = 1.58620, acc = 0.49018\n",
      "[ Train | 014/080 ] loss = 0.90058, acc = 0.69047\n",
      "[ Valid | 014/080 ] loss = 1.32809, acc = 0.56716\n",
      "[ Train | 015/080 ] loss = 0.84510, acc = 0.71107\n",
      "[ Valid | 015/080 ] loss = 1.24980, acc = 0.60744\n",
      "[ Train | 016/080 ] loss = 0.80502, acc = 0.72560\n",
      "[ Valid | 016/080 ] loss = 1.18261, acc = 0.61657\n",
      "[ Train | 017/080 ] loss = 0.76857, acc = 0.73553\n",
      "[ Valid | 017/080 ] loss = 1.00724, acc = 0.67391\n",
      "[ Train | 018/080 ] loss = 0.71824, acc = 0.75391\n",
      "[ Valid | 018/080 ] loss = 1.02371, acc = 0.67232\n",
      "[ Train | 019/080 ] loss = 0.68741, acc = 0.76825\n",
      "[ Valid | 019/080 ] loss = 1.15697, acc = 0.64405\n",
      "[ Train | 020/080 ] loss = 0.65065, acc = 0.77893\n",
      "[ Valid | 020/080 ] loss = 1.20318, acc = 0.65982\n",
      "[ Train | 021/080 ] loss = 0.61392, acc = 0.79204\n",
      "[ Valid | 021/080 ] loss = 1.05387, acc = 0.66210\n",
      "[ Train | 022/080 ] loss = 0.58216, acc = 0.80025\n",
      "[ Valid | 022/080 ] loss = 1.18722, acc = 0.63998\n",
      "[ Train | 023/080 ] loss = 0.55188, acc = 0.81008\n",
      "[ Valid | 023/080 ] loss = 1.14836, acc = 0.65794\n",
      "[ Train | 024/080 ] loss = 0.53337, acc = 0.81616\n",
      "[ Valid | 024/080 ] loss = 1.02365, acc = 0.69246\n",
      "[ Train | 025/080 ] loss = 0.48718, acc = 0.83043\n",
      "[ Valid | 025/080 ] loss = 0.97315, acc = 0.70833\n",
      "[ Train | 026/080 ] loss = 0.47613, acc = 0.83650\n",
      "[ Valid | 026/080 ] loss = 0.91425, acc = 0.72599\n",
      "[ Train | 027/080 ] loss = 0.44861, acc = 0.84447\n",
      "[ Valid | 027/080 ] loss = 1.24984, acc = 0.61964\n",
      "[ Train | 028/080 ] loss = 0.41416, acc = 0.85586\n",
      "[ Valid | 028/080 ] loss = 1.06479, acc = 0.68631\n",
      "[ Train | 029/080 ] loss = 0.41024, acc = 0.85832\n",
      "[ Valid | 029/080 ] loss = 0.97632, acc = 0.73294\n",
      "[ Train | 030/080 ] loss = 0.35425, acc = 0.87925\n",
      "[ Valid | 030/080 ] loss = 0.96050, acc = 0.71399\n",
      "[ Train | 031/080 ] loss = 0.33251, acc = 0.88687\n",
      "[ Valid | 031/080 ] loss = 0.99918, acc = 0.73185\n",
      "[ Train | 032/080 ] loss = 0.31791, acc = 0.89032\n",
      "[ Valid | 032/080 ] loss = 1.12800, acc = 0.70546\n",
      "[ Train | 033/080 ] loss = 0.28673, acc = 0.89935\n",
      "[ Valid | 033/080 ] loss = 0.96755, acc = 0.73353\n",
      "[ Train | 034/080 ] loss = 0.27221, acc = 0.90838\n",
      "[ Valid | 034/080 ] loss = 0.99510, acc = 0.73740\n",
      "[ Train | 035/080 ] loss = 0.25383, acc = 0.91329\n",
      "[ Valid | 035/080 ] loss = 1.07153, acc = 0.70923\n",
      "[ Train | 036/080 ] loss = 0.21044, acc = 0.92820\n",
      "[ Valid | 036/080 ] loss = 0.97528, acc = 0.74673\n",
      "[ Train | 037/080 ] loss = 0.20534, acc = 0.93183\n",
      "[ Valid | 037/080 ] loss = 0.95773, acc = 0.73849\n",
      "[ Train | 038/080 ] loss = 0.20540, acc = 0.92994\n",
      "[ Valid | 038/080 ] loss = 1.22139, acc = 0.68532\n",
      "[ Train | 039/080 ] loss = 0.18288, acc = 0.94094\n",
      "[ Valid | 039/080 ] loss = 1.06634, acc = 0.73800\n",
      "[ Train | 040/080 ] loss = 0.16923, acc = 0.94300\n",
      "[ Valid | 040/080 ] loss = 1.08653, acc = 0.72083\n",
      "[ Train | 041/080 ] loss = 0.17147, acc = 0.94355\n",
      "[ Valid | 041/080 ] loss = 1.05686, acc = 0.72996\n",
      "[ Train | 042/080 ] loss = 0.15685, acc = 0.94873\n",
      "[ Valid | 042/080 ] loss = 0.98058, acc = 0.74365\n",
      "[ Train | 043/080 ] loss = 0.14008, acc = 0.95496\n",
      "[ Valid | 043/080 ] loss = 1.00572, acc = 0.74454\n",
      "[ Train | 044/080 ] loss = 0.12424, acc = 0.96087\n",
      "[ Valid | 044/080 ] loss = 1.20272, acc = 0.69802\n",
      "[ Train | 045/080 ] loss = 0.12572, acc = 0.95808\n",
      "[ Valid | 045/080 ] loss = 1.07713, acc = 0.73651\n",
      "[ Train | 046/080 ] loss = 0.12594, acc = 0.95866\n",
      "[ Valid | 046/080 ] loss = 1.01935, acc = 0.73016\n",
      "[ Train | 047/080 ] loss = 0.11935, acc = 0.96234\n",
      "[ Valid | 047/080 ] loss = 1.30744, acc = 0.69722\n",
      "[ Train | 048/080 ] loss = 0.11218, acc = 0.96284\n",
      "[ Valid | 048/080 ] loss = 1.08860, acc = 0.72599\n",
      "[ Train | 049/080 ] loss = 0.12067, acc = 0.96185\n",
      "[ Valid | 049/080 ] loss = 1.26437, acc = 0.69673\n",
      "[ Train | 050/080 ] loss = 0.10579, acc = 0.96604\n",
      "[ Valid | 050/080 ] loss = 1.09836, acc = 0.73294\n",
      "[ Train | 051/080 ] loss = 0.12863, acc = 0.95595\n",
      "[ Valid | 051/080 ] loss = 1.00887, acc = 0.76052\n",
      "[ Train | 052/080 ] loss = 0.10113, acc = 0.96726\n",
      "[ Valid | 052/080 ] loss = 1.27265, acc = 0.70794\n",
      "[ Train | 053/080 ] loss = 0.09228, acc = 0.97030\n",
      "[ Valid | 053/080 ] loss = 1.23367, acc = 0.70992\n",
      "[ Train | 054/080 ] loss = 0.10780, acc = 0.96275\n",
      "[ Valid | 054/080 ] loss = 1.03045, acc = 0.74921\n",
      "[ Train | 055/080 ] loss = 0.07951, acc = 0.97415\n",
      "[ Valid | 055/080 ] loss = 1.03199, acc = 0.75258\n",
      "[ Train | 056/080 ] loss = 0.07082, acc = 0.97907\n",
      "[ Valid | 056/080 ] loss = 1.00274, acc = 0.74633\n",
      "[ Train | 057/080 ] loss = 0.07221, acc = 0.97843\n",
      "[ Valid | 057/080 ] loss = 1.39217, acc = 0.69831\n",
      "[ Train | 058/080 ] loss = 0.07638, acc = 0.97654\n",
      "[ Valid | 058/080 ] loss = 1.14644, acc = 0.72490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-125:\n",
      "Traceback (most recent call last):\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/environment/python/versions/3.7.12/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23162/3298656155.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Calculate the cross-entropy loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# We don't need to apply softmax before computing cross-entropy as it is done automatically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Gradients stored in the parameters in the previous step should be cleared out first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = ResNet18().to(device)\n",
    "model.device = device\n",
    "\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.9, weight_decay=5e-4)\n",
    "n_epochs = 80\n",
    "best_acc = 0.0\n",
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    for batch in (train_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "\n",
    "        logits = model(imgs.to(device))\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        \n",
    "\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    \n",
    "    train_acc_list.append(float(train_acc))\n",
    "    \n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for batch in (valid_loader):\n",
    "\n",
    "        imgs, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "          logits = model(imgs.to(device))\n",
    "\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "    if valid_acc > best_acc:\n",
    "        torch.save(model.state_dict(), \"base_model.pt\")\n",
    "        best_acc = valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5086d56-5cbf-4b82-8c48-63a5cd39c504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
